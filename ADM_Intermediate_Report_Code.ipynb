{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas 및 Numpy 패키지 불러오기\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "# 청소년 건강행태조사 2016년, 2017년, 2018년도 데이터 불러오기\n",
    "df16_og = pd.read_sas('/content/drive/My Drive/고급데이터마이닝/청건행 데이터셋/kyrbs2016.sas7bdat')\n",
    "df17_og = pd.read_sas('/content/drive/My Drive/고급데이터마이닝/청건행 데이터셋/kyrbs2017.sas7bdat')\n",
    "df18_og = pd.read_sas('/content/drive/My Drive/ 고급데이터마이닝/청건행 데이터셋 /kyrbs2018.sas7bdat')\n",
    "\n",
    "# 분석용 데이터셋 저장하기\n",
    "df16 = df16_og.copy()\n",
    "df17 = df17_og.copy()\n",
    "df18 = df18_og.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 청소년 건강행태조사 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청소년 건강행태조사 파일 하나로 합치기\n",
    "cgh = pd.concat([df16, df17, df18])\n",
    "\n",
    "# 선행 연구(논문) 기반 유의미한 변수 추출\n",
    "df_att = cgh[[\"sex\",\"age\",\"D_1_1\",\"Total_slp_wd\",\"BP1\",\"BO1\",\"BE5_1\",\"BE8_1\",\"BE8_2\",\"BP5\",\"HE_ht\",\"HE_wt\"]]\n",
    "\n",
    "#히스토그램 산출 ( 탐색적 분석 )\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "for df in [\"sex\",\"age\",\"D_1_1\",\"Total_slp_wd\",\"BP1\",\"BO1\",\"BE5_1\",\"BE8_1\",\"BE8_2\",\"BP5\",\"HE_ht\",\"HE_wt\"]:\n",
    "    plt.hist(df_att[df])\n",
    "    plt.ylabel('frequency')\n",
    "    plt.title('Histogram of {}'.format(df))\n",
    "    plt.show()\n",
    "\n",
    "# 분석에 사용할 변수만 추출\n",
    "cgh = cgh.loc[:,['HT','WT','SEX','AGE','M_SLP_HR','M_SLP_MM','M_WK_HR','M_WK_MM','M_SLP_HR_K','M_SLP_MM_K','M_WK_HR_K','M_WK_MM_K','PR_HT','M_STR','PR_BI','PA_MSC','PA_SWD_S','PA_SWD_N','PA_SWK_S','PA_SWK_N','M_SAD']]\n",
    "\n",
    "# 청소년 건강행태조사 분석 대상 데이터셋 Instance 개수 및 변수 개수 확인\n",
    "cgh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앉은시간 변수 생성\n",
    "cgh['SitTime'] = ((cgh['PA_SWD_S'] + cgh['PA_SWD_N'])*5 + (cgh['PA_SWK_S'] + cgh['PA_SWK_N'])*2)/7\n",
    "cgh['SitTime'].describe()\n",
    "\n",
    "\n",
    "# 앉은시간 boxplot\n",
    "cgh.boxplot(column = 'SitTime')\n",
    "\n",
    "# 인덱스 초기화\n",
    "cgh = cgh.reset_index()\n",
    "cgh = cgh.iloc[:,1:]\n",
    "cgh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주중 (월~금) 수면시간 전처리\n",
    "for i in range(len(cgh[\"M_SLP_HR\"])):\n",
    "    if cgh[\"M_SLP_HR\"][i]<=12:\n",
    "        cgh[\"M_SLP_HR\"][i] += 24\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if cgh[\"M_WK_HR\"][i]<=12:\n",
    "        cgh[\"M_WK_HR\"][i] +=24\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for i in range(len(cgh[\"M_SLP_HR\"])):\n",
    "    cgh[\"SLP_WK\"] = (cgh[\"M_WK_HR\"]*60 + cgh[\"M_WK_MM\"])-(cgh[\"M_SLP_HR\"]*60 + cgh[\"M_SLP_MM\"])\n",
    "\n",
    "# 생선된 변수 기초통계량 확인 (Instance 개수, 평균값, 4분위수 등)\n",
    "cgh[\"SLP_WK\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평소 스테레스 인지 정도에서 값이 5인 행들 삭제하기 (국민건강영양조사 데이터와 합치기 위한 작업)\n",
    "idx_nm = cgh[cgh[\"M_STR\"] == 5].index\n",
    "cgh = cgh.drop(idx_nm)\n",
    "cgh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2주 이상 연속 우울감 여부 값 바꾸기\n",
    "cgh = cgh.replace({\"M_SAD\":1},{\"M_SAD\":3})\n",
    "cgh = cgh.replace({\"M_SAD\":2},{\"M_SAD\":1})\n",
    "cgh = cgh.replace({\"M_SAD\":3},{\"M_SAD\":2})\n",
    "cgh[\"M_SAD\"].value_counts() # 1:예   2:아니오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI [BMI] (명목) 변수 생성\n",
    "cgh['BMI'] = (cgh['WT'] / (cgh['HT'] / 100)**2)\n",
    "cgh.loc[cgh['BMI'] < 25, 'BMI'] = 0\n",
    "cgh.loc[cgh['BMI'] >= 25, 'BMI'] = 1\n",
    "cgh['BMI'] = cgh['BMI'].astype('category')\n",
    "print(cgh['BMI'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(cgh['BMI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청건행 변수명을 국건영과 동일하게 바꾸기\n",
    "df = cgh.rename(columns = {'SEX':'sex','AGE':'age','PR_HT':'D_1_1','M_STR':'BP1','PR_BI':'BO1','PA_MSC':'BE5_1','M_SAD':'BP5', 'SLP_WK':'Total_slp_wd'})\n",
    "\n",
    "# 필요한 Column만 불러오기\n",
    "df_cgh = df.loc[:,['sex', 'age', 'D_1_1', 'BP1', 'BO1', 'BE5_1', 'BP5', 'BMI', 'Total_slp_wd', 'SitTime']]\n",
    "df_cgh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 국민 건강 영양조사 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16 = pd.read_sas('/content/drive/My Drive/고급데이터마이닝/국건영 원본 데이터셋/hn16_all.sas7bdat')\n",
    "df_16\n",
    "\n",
    "df_17 = pd.read_sas('/content/drive/My Drive/고급데이터마이닝/국건영 원본 데이터셋/hn17_all.sas7bdat')\n",
    "df_17\n",
    "\n",
    "df_18 = pd.read_sas('/content/drive/My Drive/고급데이터마이닝/국건영 원본 데이터셋/hn18_all.sas7bdat')\n",
    "df_18\n",
    "\n",
    "# 국민건강영양조사 2016년 ~ 2018년 데이터 하나로 합치기\n",
    "# 추후에는 국민건강영양조사 2018년도 데이터만 사용함\n",
    "df_kky = pd.concat([df_16,df_17,df_18])\n",
    "\n",
    "# 선행 연구(논문) 기반 유의미한 변수 추출\n",
    "df_att = df_kky[[\"sex\",\"age\",\"D_1_1\",\"Total_slp_wd\",\"BP1\",\"BO1\",\"BE5_1\",\"BE8_1\",\"BE8_2\",\"BP5\",\"HE_ht\",\"HE_wt\"]]\n",
    "\n",
    "#히스토그램 산출 ( 탐색적 분석 )\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "for df in [\"sex\",\"age\",\"D_1_1\",\"Total_slp_wd\",\"BP1\",\"BO1\",\"BE5_1\",\"BE8_1\",\"BE8_2\",\"BP5\",\"HE_ht\",\"HE_wt\"]:\n",
    "    plt.hist(df_att[df])\n",
    "    plt.ylabel('frequency')\n",
    "    plt.title('Histogram of {}'.format(df))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 청건행 데이터 및 국건영 데이터 합친 후 최종 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석에 사용한 변수만 추출하여 새로운 데이터셋 구성\n",
    "df_att = df_kky[[\"sex\",\"age\",\"D_1_1\",\"Total_slp_wk\",\"BP1\",\"BO1\",\"BE5_1\",\"BE8_1\",\"BE8_2\",\"BP5\",\"HE_ht\",\"HE_wt\"]]\n",
    "\n",
    "# 주중(Weekday)라는 단어와 혼동이 있어서 Total_slp_wk를 Total_slp_wd로 변경\n",
    "df_att.rename(columns = {'Total_slp_wk': 'Total_slp_wd'), inplace = True)  \n",
    "\n",
    "# 인덱스 초기화\n",
    "df_att = df_att.reset_index()\n",
    "df_att = df_att.iloc[:,1:]\n",
    "df_att.shape\n",
    "                                                                       \n",
    "# 변수별 Instance, 결측치, 데이터 타입 확인\n",
    "df_att.info()\n",
    "# BMI [BMI] (명목) 변수 생성\n",
    "df_att['BMI'] = (df_att['HE_wt'] / (df_att['HE_ht'] / 100)**2)\n",
    "df_att.loc[df_att['BMI'] < 25, 'BMI'] = 0\n",
    "df_att.loc[df_att['BMI'] >= 25, 'BMI'] = 1\n",
    "print(df_att['BMI'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(df_att['BMI'])\n",
    "\n",
    "# 청소년 (만12세~18세) 데이터 생성\n",
    "df_att = df_att.loc[(df_att['age']>=12) & (df_att['age']<=18), :]  \n",
    "df_att.info()\n",
    "\n",
    "df_att.loc[(df_att['BE8_1'] == 88) | (df_att['BE8_1'] == 99) , 'BE8_1'] = np.nan \n",
    "df_att.loc[(df_att['BE8_2'] == 88) | (df_att['BE8_2'] == 99) , 'BE8_2'] = np.nan \n",
    "\n",
    "# 하루 평균 앉아서 보내는 시간(분 단위) 변수 생성\n",
    "df_att[\"SitTime\"] = df_att[\"BE8_1\"]*60 + df_att['BE8_2']\n",
    "df_att[\"SitTime\"].describe()\n",
    "\n",
    "# 전처리된 청소년건강행태조사 데이터 및 국민건강영양조사 데이터 합치기\n",
    "df_final = pd.concat([df_att,df_cgh])\n",
    "df_final.shape\n",
    "\n",
    "# 최종 분석 대상 데이터 변수, 변수별 Instance 및 결측치 개수, 데이터 타입 확인 \n",
    "df_final.info()\n",
    "\n",
    "df_final['BMI'] = df_final['BMI'].astype('category')\n",
    "\n",
    "df_final = df_final.loc[:,['sex','age','D_1_1','BP1','BO1','BE5_1','BP5','BMI','Total_slp_wk','SitTime']]\n",
    "\n",
    "# 1주일간 근력운동 일수 (등간)\n",
    "print(df_final['BE5_1'].value_counts()) # 8 비해당 929명, 9 모름, 무응답 : 267명 -> NA\n",
    "df_final.loc[(df_final['BE5_1'] == 8) |(df_final['BE5_1'] == 9) , 'BE5_1'] = np.nan  #na 값 처리\n",
    "print(df_final['BE5_1'].value_counts())\n",
    "\n",
    "# 주관적 건강상태 [D_1_1]] (서열)\n",
    "from pandas.api.types import CategoricalDtype\n",
    "print(df_final['D_1_1'].value_counts())\n",
    "print(\"==========================\")\n",
    "df_final.loc[df_final['D_1_1'] == 9, 'D_1_1'] = np.nan\n",
    "df_final['D_1_1'] = df_final['D_1_1'].astype(CategoricalDtype(ordered=True))\n",
    "print(df_final['D_1_1'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(df_final['D_1_1'])\n",
    "\n",
    "# 2주 이상 연속 우울감 여부 [BP5] (명목)\n",
    "print(df_final['BP5'].value_counts())\n",
    "print(\"==========================\")\n",
    "df_final.loc[df_final['BP5'] == 8, 'BP5'] = np.nan\n",
    "df_final.loc[df_final['BP5'] == 9, 'BP5'] = np.nan\n",
    "df_final['BP5'] = df_final['BP5'].astype('category')\n",
    "print(df_final['BP5'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(df_final['BP5'])\n",
    "\n",
    "# 평소 스트레스 인지정도 [BP1] (서열)\n",
    "print(df_final['BP1'].value_counts())\n",
    "print(\"==========================\")\n",
    "df_final.loc[df_final['BP1'] == 8, 'BP1'] = np.nan\n",
    "df_final.loc[df_final['BP1'] == 9, 'BP1'] = np.nan\n",
    "\n",
    "df_final['BP1'] = df_final['BP1'].astype(CategoricalDtype(ordered=True))\n",
    "print(df_final['BP1'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(df_final['BP1'])\n",
    "\n",
    "# 주관적 체형 인지 [BO1] (서열)\n",
    "print(df_final['BO1'].value_counts())\n",
    "print(\"==========================\")\n",
    "df_final.loc[df_final['BO1'] == 8, 'BO1'] = np.nan\n",
    "df_final.loc[df_final['BO1'] == 9, 'BO1'] = np.nan\n",
    "\n",
    "df_final['BO1'] = df_final['BO1'].astype(CategoricalDtype(ordered=True))\n",
    "print(df_final['BO1'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(df_final['BO1'])\n",
    "# 1주일간 근력운동 일수 [BE5_1]] (서열)\n",
    "print(df_final['BE5_1'].value_counts())\n",
    "print(\"==========================\")\n",
    "df_final['BE5_1'] = df_final['BE5_1'].astype(CategoricalDtype(ordered=True))\n",
    "print(df_final['BE5_1'].value_counts())\n",
    "print(\"==========================\")\n",
    "print(df_final['BE5_1'])\n",
    "\n",
    "df_final['sex'] = df_final['sex'].astype('category')\n",
    "\n",
    "# 서열 척도 및 명목 척도 적용 후 변수별 데이터 타입 확인\n",
    "df_final.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결측치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고사항 : \n",
    "- 결측치가 있는 행 제거, 즉 완전제거법 적용한 데이터셋 이름 : df_all\n",
    "- 평균값 대체 적용한 데이터셋 이름 : df_mean\n",
    "- 중앙값 대체 적용한 데이터셋 이름 : df_median\n",
    "- 최빈값 대체 적용한 데이터셋 이름 : df_mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 있는 행 제거\n",
    "df_new = df_final.dropna(axis=0)\n",
    "df_new = df_new.reset_index()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "transformer = StandardScaler()\n",
    "standard = transformer.fit_transform(df_new.loc[:,['Total_slp_wd','SitTime']])\n",
    "df_standard = pd.DataFrame(standard, columns = ['Total_slp_wd_standard','SitTime_standard'])\n",
    "df_standard = pd.concat([df_new, df_standard], axis = 1)\n",
    "df_standard\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled = min_max_scaler.fit_transform(df_new.loc[:,['Total_slp_wd','SitTime']])\n",
    "df_scaled = pd.DataFrame(scaled, columns = ['Total_slp_wd_scaled','SitTime_scaled'])\n",
    "df_all = pd.concat([df_standard, df_scaled], axis=1)\n",
    "df_all = df_all.iloc[:,1:]\n",
    "df_all\n",
    "# 평균값 대체\n",
    "df_csn_mean = df_final.copy()\n",
    "\n",
    "print(df_csn_mean.isnull().sum())\n",
    "df_csn_mean.fillna({'D_1_1':int(df_csn_mean['D_1_1'].mode()),\n",
    "                    'BP1':int(df_csn_mean['BP1'].mode()),\n",
    "                    'BO1':int(df_csn_mean['BO1'].mode()),\n",
    "                    'BP5':int(df_csn_mean['BP5'].mode()),\n",
    "                    'BMI':int(df_csn_mean['BMI'].mode()),\n",
    "                    'BE5_1':int(df_csn_mean['BE5_1'].mode()),\n",
    "                    'age':int(df_csn_mean['age'].mean()),\n",
    "                    'Total_slp_wd':df_csn_mean['Total_slp_wd'].mean(),\n",
    "                    'SitTime':df_csn_mean['SitTime'].mean()}, inplace=True)\n",
    "print('========================')\n",
    "print(df_csn_mean.isnull().sum())\n",
    "\n",
    "# 평균값 대체 자료에 표준화 및 정규화\n",
    "\n",
    "# 인덱스 초기화\n",
    "df_csn_mean.reset_index(inplace=True)\n",
    "df_csn_mean = df_csn_mean.iloc[:,1:]\n",
    "\n",
    "## 정규화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "transformer = StandardScaler()\n",
    "standard = transformer.fit_transform(df_csn_mean.loc[:,['Total_slp_wd','SitTime']])\n",
    "df_standard = pd.DataFrame(standard, columns = ['Total_slp_wd_standard','SitTime_standard'])\n",
    "\n",
    "## Min-Max Scaling\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled = min_max_scaler.fit_transform(df_csn_mean.loc[:,['Total_slp_wd','SitTime']])\n",
    "df_scaled = pd.DataFrame(scaled, columns = ['Total_slp_wd_scaled','SitTime_scaled'])\n",
    "\n",
    "## 합치기\n",
    "df_mean = pd.concat([df_csn_mean, df_standard, df_scaled], axis=1)\n",
    "df_mean.info()\n",
    "\n",
    "# 중앙값 대체 \n",
    "\n",
    "df_csn_median = df_final.copy()\n",
    "\n",
    "print(df_csn_median.isnull().sum())\n",
    "df_csn_median.fillna({'D_1_1':int(df_csn_median['D_1_1'].mode()),\n",
    "                    'BP1':int(df_csn_median['BP1'].mode()),\n",
    "                    'BO1':int(df_csn_median['BO1'].mode()),\n",
    "                    'BP5':int(df_csn_median['BP5'].mode()),\n",
    "                    'BMI':int(df_csn_median['BMI'].mode()),\n",
    "                    'BE5_1':int(df_csn_median['BE5_1'].mode()),\n",
    "                    'age':int(df_csn_mean['age'].median()),\n",
    "                    'Total_slp_wd':df_csn_median['Total_slp_wd'].median(),\n",
    "                    'SitTime':df_csn_median['SitTime'].median()}, inplace=True)\n",
    "print('========================')\n",
    "print(df_csn_median.isnull().sum())\n",
    "\n",
    "## 인덱스 초기화\n",
    "df_csn_median.reset_index(inplace=True)\n",
    "df_csn_median = df_csn_median.iloc[:,1:]\n",
    "\n",
    "## 정규화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "transformer = StandardScaler()\n",
    "standard = transformer.fit_transform(df_csn_median.loc[:,['Total_slp_wd','SitTime']])\n",
    "df_standard = pd.DataFrame(standard, columns = ['Total_slp_wd_standard','SitTime_standard'])\n",
    "\n",
    "## Min-Max Scaling\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled = min_max_scaler.fit_transform(df_csn_median.loc[:,['Total_slp_wd','SitTime']])\n",
    "df_scaled = pd.DataFrame(scaled, columns = ['Total_slp_wd_scaled','SitTime_scaled'])\n",
    "\n",
    "## 합치기\n",
    "df_median = pd.concat([df_csn_median, df_standard, df_scaled], axis=1)\n",
    "df_median.info()\n",
    "\n",
    "\n",
    "# 최빈값 대체\n",
    "df_csn_mode = df_final.copy()\n",
    "\n",
    "print(df_csn_mode.isnull().sum())\n",
    "df_csn_mode.fillna({'D_1_1':int(df_csn_mode['D_1_1'].mode()),\n",
    "                    'BP1':int(df_csn_mode['BP1'].mode()),\n",
    "                    'BO1':int(df_csn_mode['BO1'].mode()),\n",
    "                    'BP5':int(df_csn_mode['BP5'].mode()),\n",
    "                    'BMI':int(df_csn_mode['BMI'].mode()),\n",
    "                    'BE5_1':int(df_csn_mode['BE5_1'].mode()),\n",
    "                    'age':int(df_csn_mean['age'].mode()),\n",
    "                    'Total_slp_wd':float(df_csn_mode['Total_slp_wd'].mode()),\n",
    "                    'SitTime':float(df_csn_mode['SitTime'].mode())}, inplace=True)\n",
    "print('========================')\n",
    "print(df_csn_mode.isnull().sum())\n",
    "\n",
    "## 인덱스 초기화\n",
    "df_csn_mode.reset_index(inplace=True)\n",
    "df_csn_mode = df_csn_mode.iloc[:,1:]\n",
    "\n",
    "## 정규화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "transformer = StandardScaler()\n",
    "standard = transformer.fit_transform(df_csn_mode.loc[:,['Total_slp_wd','SitTime']])\n",
    "df_standard = pd.DataFrame(standard, columns = ['Total_slp_wd_standard','SitTime_standard'])\n",
    "\n",
    "## Min-Max Scaling\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled = min_max_scaler.fit_transform(df_csn_mode.loc[:,['Total_slp_wd','SitTime']])\n",
    "df_scaled = pd.DataFrame(scaled, columns = ['Total_slp_wd_scaled','SitTime_scaled'])\n",
    "\n",
    "## 합치기\n",
    "df_mode = pd.concat([df_csn_mode, df_standard, df_scaled], axis=1)\n",
    "df_mode.info()\n",
    "\n",
    "# csv 파일로 저장하기\n",
    "df_all.to_csv(‘df_all.csv’)\n",
    "df_mean.to_csv(‘df_mean.csv’)\n",
    "df_median.to_csv(‘df_median.csv’)\n",
    "df_mode.to_csv(‘df_mode.csv’)\n",
    "\n",
    "# 결측치 처리한 데이터별 Instance 및 변수 개수 확인\n",
    "print(df_all.shape)\n",
    "print(df_mean.shape)\n",
    "print(df_median.shape)\n",
    "print(df_mode.shape)\n",
    "\n",
    "#남자 데이터 만들기\n",
    "df_all_b = df_all.loc[df_all[\"sex\"]==1,:]\n",
    "df_all_b = df_all_b.drop('sex', axis = 1)\n",
    "\n",
    "df_mean_b = df_mean.loc[df_mean[\"sex\"]==1,:]\n",
    "df_mean_b = df_mean_b.drop('sex', axis = 1)\n",
    "\n",
    "df_median_b = df_median.loc[df_median[\"sex\"]==1,:]\n",
    "df_median_b = df_median_b.drop('sex', axis = 1)\n",
    "\n",
    "df_mode_b = df_mode.loc[df_mode[\"sex\"]==1,:]\n",
    "df_mode_b = df_mode_b.drop('sex', axis = 1)\n",
    "\n",
    "df_all_b.shape, df_mean_b.shape, df_median_b.shape, df_mode_b.shape\n",
    "\n",
    "#여자 데이터 만들기\n",
    "df_all_g = df_all.loc[df_all[\"sex\"]==2,:]\n",
    "df_all_g = df_all_g.drop('sex', axis = 1)\n",
    "\n",
    "df_mean_g = df_mean.loc[df_mean[\"sex\"]==2,:]\n",
    "df_mean_g = df_mean_g.drop('sex', axis = 1)\n",
    "\n",
    "df_median_g = df_median.loc[df_median[\"sex\"]==2,:]\n",
    "df_median_g = df_median_g.drop('sex', axis = 1)\n",
    "\n",
    "df_mode_g = df_mode.loc[df_mode[\"sex\"]==2,:]\n",
    "df_mode_g = df_mode_g.drop('sex', axis = 1)\n",
    "\n",
    "df_all_g.shape, df_mean_g.shape, df_median_g.shape, df_mode_g.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분석 대상 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 행 제거 파일\n",
    "df_all = pd.read_csv('/content/drive/My Drive/고급데이터마이닝/df_all.csv')\n",
    "df_all = df_all.iloc[:,1:]\n",
    "df_all\n",
    "\n",
    "for i in df_all.columns:\n",
    "  if i in ['Total_slp_wd','SitTime','Total_slp_wd_standard','SitTime_standard','Total_slp_wd_scaled','SitTime_scaled']:\n",
    "    pass\n",
    "  else:\n",
    "    df_all[i] = df_all[i].astype('category')\n",
    "\n",
    "# 남녀 데이터 생성\n",
    "df_all_b = df_all.loc[df_all[\"sex\"]==1,:]\n",
    "df_all_g = df_all.loc[df_all[\"sex\"]==2,:]\n",
    "df_all_b = df_all_b.drop('sex', axis = 1)\n",
    "df_all_g = df_all_g.drop('sex', axis = 1)\n",
    "\n",
    "# 평균값 대체 파일\n",
    "df_mean = pd.read_csv('/content/drive/My Drive/고급데이터마이닝/평균, 중앙값, 최빈값 대체 데이터/df_mean.csv')\n",
    "df_mean = df_mean.iloc[:,1:]\n",
    "df_mean\n",
    "\n",
    "for i in df_mean.columns:\n",
    "  if i in ['Total_slp_wd','SitTime','Total_slp_wd_standard','SitTime_standard','Total_slp_wd_scaled','SitTime_scaled']:\n",
    "    pass\n",
    "  else:\n",
    "    df_mean[i] = df_mean[i].astype('category')\n",
    "\n",
    "# 남녀 데이터 생성 \n",
    "df_mean_b = df_mean.loc[df_mean[\"sex\"]==1,:]\n",
    "df_mean_g = df_mean.loc[df_mean[\"sex\"]==2,:]\n",
    "df_mean_b = df_mean_b.drop('sex', axis = 1)\n",
    "df_mean_g = df_mean_g.drop('sex', axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 중앙값 대체 파일\n",
    "df_median = pd.read_csv('/content/drive/My Drive/고급데이터마이닝/평균, 중앙값, 최빈값 대체 데이터/df_median.csv')\n",
    "df_median = df_median.iloc[:,1:]\n",
    "df_median\n",
    "\n",
    "for i in df_median.columns:\n",
    "  if i in ['Total_slp_wd','SitTime','Total_slp_wd_standard','SitTime_standard','Total_slp_wd_scaled','SitTime_scaled']:\n",
    "    pass\n",
    "  else:\n",
    "    df_median[i] = df_median[i].astype('category')\n",
    "\n",
    "# 남녀 데이터 생성 \n",
    "df_median_b = df_median.loc[df_median[\"sex\"]==1,:]\n",
    "df_median_g = df_median.loc[df_median[\"sex\"]==2,:]\n",
    "df_median_b = df_median_b.drop('sex', axis = 1)\n",
    "df_median_g = df_median_g.drop('sex', axis = 1)\n",
    "\n",
    "\n",
    "# 최빈값 대체 파일\n",
    "df_mode = pd.read_csv('/content/drive/My Drive/고급데이터마이닝/평균, 중앙값, 최빈값 대체 데이터/df_mode.csv')\n",
    "df_mode = df_mode.iloc[:,1:]\n",
    "df_mode\n",
    "\n",
    "for i in df_mode.columns:\n",
    "    if i in ['Total_slp_wd','SitTime','Total_slp_wd_standard','SitTime_standard','Total_slp_wd_scaled','SitTime_scaled']:\n",
    "        pass\n",
    "      else:\n",
    "        df_mode[i] = df_mode[i].astype('category')\n",
    "\n",
    "# 남녀 데이터 생성 \n",
    "df_mode_b = df_mode.loc[df_mode[\"sex\"]==1,:]\n",
    "df_mode_g = df_mode.loc[df_mode[\"sex\"]==2,:]\n",
    "df_mode_b = df_mode_b.drop('sex', axis = 1)\n",
    "df_mode_g = df_mode_g.drop('sex', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def model_evaluation(label, predict):\n",
    "    cf_matrix = confusion_matrix(label, predict)\n",
    "    Accuracy = (cf_matrix[0][0] + cf_matrix[1][1]) / sum(sum(cf_matrix))\n",
    "    Precision = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[0][1])\n",
    "    Recall = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[1][0])\n",
    "    Specificity = cf_matrix[0][0] / (cf_matrix[0][0] + cf_matrix[0][1])\n",
    "    F1_Score = (2 * Recall * Precision) / (Recall + Precision)\n",
    "    \n",
    "    print(\"Accuracy: \", Accuracy)\n",
    "    print(\"Precision: \", Precision)\n",
    "    print(\"Recall: \", Recall)\n",
    "    print(\"Specificity: \", Specificity)\n",
    "    print(\"F1-Score: \", F1_Score)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for df in [df_all_g, df_mean_g, df_median_g, df_mode_g]:\n",
    "    for column in [['Total_slp_wd_scaled','SitTime_scaled','Total_slp_wd_standard','SitTime_standard','BMI'],\n",
    "                                                    ['Total_slp_wd_scaled','SitTime_scaled','Total_slp_wd','SitTime','BMI'],\n",
    "                                                    ['Total_slp_wd_standard','SitTime_standard','Total_slp_wd','SitTime','BMI']]:\n",
    "        \n",
    "        count = count+1\n",
    "        \n",
    "        if count == 1 or count  == 2 or count == 3:\n",
    "            print('제목: df_all_g')\n",
    "        elif count == 4 or count  == 5 or count == 6:\n",
    "            print('제목: df_mean_g')\n",
    "        elif count == 7 or count  == 8 or count == 9:\n",
    "            print('제목: df_median_g')\n",
    "        elif count == 10 or count  == 11 or count == 12:\n",
    "            print('제목: df_mode_g')\n",
    "\n",
    "        \n",
    "        if count == 1 or count  == 4 or count == 7 or count == 10 :\n",
    "            print('데이터: 원본')\n",
    "        elif count == 2 or count  == 5 or count == 8 or count == 11:\n",
    "            print('제목: Standard')\n",
    "        elif count == 3 or count  == 6 or count == 9 or count == 12:\n",
    "            print('제목: Scaled')\n",
    "\n",
    "        \n",
    "        X = df.drop(column,axis=1) \n",
    "        y = df['BMI']\n",
    "\n",
    "        # test_size : 테스트 데이터셋의 비율(float)이나 갯수(int) \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=3)\n",
    "\n",
    "        # 파라메터 후보\n",
    "        param_grid = {\n",
    "            'var_smoothing': [1e-8, 1e-9, 1e-10]\n",
    "        }\n",
    "\n",
    "        # 그리드 서치 진행\n",
    "        grid_search = GridSearchCV(GaussianNB(), param_grid, cv=10)        \n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        grid_search.score(X_test, y_test)\n",
    "        print(\"best parameters : {}\".format(grid_search.best_params_))\n",
    "        \n",
    "        predicted = grid_search.predict(X_test)\n",
    "        print(confusion_matrix(y_test, predicted))\n",
    "        print(model_evaluation(y_test, predicted))\n",
    "\n",
    "        #print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
    "        print('='*40)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "def model_evaluation(label, predict):\n",
    "    cf_matrix = confusion_matrix(label, predict)\n",
    "    Accuracy = (cf_matrix[0][0] + cf_matrix[1][1]) / sum(sum(cf_matrix))\n",
    "    Precision = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[0][1])\n",
    "    Recall = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[1][0])\n",
    "    Specificity = cf_matrix[0][0] / (cf_matrix[0][0] + cf_matrix[0][1])\n",
    "    F1_Score = (2 * Recall * Precision) / (Recall + Precision)\n",
    "    \n",
    "    print(\"Accuracy: \", round(Accuracy,3))\n",
    "    print(\"Precision: \", round(Precision,3))\n",
    "    print(\"Recall: \", round(Recall,3))\n",
    "    print(\"Specificity: \", round(Specificity,3))\n",
    "    print(\"F1-Score: \", round(F1_Score,3))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for df in [df_all_b, df_mean_b, df_median_b, df_mode_b]:\n",
    "    for column in [['Total_slp_wd_scaled','SitTime_scaled','Total_slp_wd_standard','SitTime_standard','BMI'],\n",
    "                                                    ['Total_slp_wd_scaled','SitTime_scaled','Total_slp_wd','SitTime','BMI'],\n",
    "                                                    ['Total_slp_wd_standard','SitTime_standard','Total_slp_wd','SitTime','BMI']]:\n",
    "        \n",
    "        count = count+1\n",
    "        \n",
    "        if count == 1 or count  == 2 or count == 3:\n",
    "            print('제목: df_all_b')\n",
    "        elif count == 4 or count  == 5 or count == 6:\n",
    "            print('제목: df_mean_b')\n",
    "        elif count == 7 or count  == 8 or count == 9:\n",
    "            print('제목: df_median_b')\n",
    "        elif count == 10 or count  == 11 or count == 12:\n",
    "            print('제목: df_mode_b')\n",
    "        \n",
    "        if count == 1 or count  == 4 or count == 7 or count == 10 :\n",
    "            print('데이터: 원본')\n",
    "        elif count == 2 or count  == 5 or count == 8 or count == 11:\n",
    "            print('제목: Standard')\n",
    "        elif count == 3 or count  == 6 or count == 9 or count == 12:\n",
    "            print('제목: Scaled')\n",
    "        \n",
    "        X = df.drop(column,axis=1) \n",
    "        y = df['BMI']\n",
    "\n",
    "        # test_size : 테스트 데이터셋의 비율(float)이나 갯수(int) \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=3)\n",
    "\n",
    "        #최적 파라미터 값 찾기\n",
    "        params = { 'n_estimators' : [10, 100],\n",
    "                   'max_depth' : [6, 8, 10, 12],\n",
    "                   'min_samples_leaf' : [8, 12, 18],\n",
    "                   'min_samples_split' : [8, 16, 20]\n",
    "                    }\n",
    "        rf_clf = RandomForestClassifier(random_state = 0, n_jobs = -1)\n",
    "        grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 5, n_jobs = -1)\n",
    "        grid_cv.fit(X_train, y_train)\n",
    "\n",
    "        predicted = grid_cv.predict(X_test)\n",
    "        print(confusion_matrix(y_test, predicted))\n",
    "        print(model_evaluation(y_test, predicted))\n",
    "\n",
    "        print('하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "        #print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
    "        print('='*40)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "for df in [df_all, df_mean, df_median, df_mode]:\n",
    "    for column in [['Total_slp_wd_scaled','SitTime_scaled','Total_slp_wd_standard','SitTime_standard','BMI'],\n",
    "                                                    ['Total_slp_wd_scaled','SitTime_scaled','Total_slp_wd','SitTime','BMI'],\n",
    "                                                    ['Total_slp_wd_standard','SitTime_standard','Total_slp_wd','SitTime','BMI']]:\n",
    "        \n",
    "        count = count+1\n",
    "        \n",
    "        if count == 1 or count  == 2 or count == 3:\n",
    "            print('제목: df_all')\n",
    "        elif count == 4 or count  == 5 or count == 6:\n",
    "            print('제목: df_mean')\n",
    "        elif count == 7 or count  == 8 or count == 9:\n",
    "            print('제목: df_median')\n",
    "        elif count == 10 or count  == 11 or count == 12:\n",
    "            print('제목: df_mode')\n",
    "\n",
    "        \n",
    "        if count == 1 or count  == 4 or count == 7 or count == 10 :\n",
    "            print('데이터: 원본')\n",
    "        elif count == 2 or count  == 5 or count == 8 or count == 11:\n",
    "            print('제목: Standard')\n",
    "        elif count == 3 or count  == 6 or count == 9 or count == 12:\n",
    "            print('제목: Scaled')\n",
    "  \n",
    "        \n",
    "        X = df.drop(column,axis=1) \n",
    "        y = df['BMI']\n",
    "\n",
    "        # test_size : 테스트 데이터셋의 비율(float)이나 갯수(int) \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=3)\n",
    "\n",
    "        # 파라메터 후보\n",
    "        param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['l1', 'l2']}\n",
    "\n",
    "        # 그리드 서치 진행\n",
    "        grid_search = GridSearchCV(LogisticRegression(solver='liblinear', random_state = 42), param_grid, cv= 5 )        \n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        grid_search.score(X_test, y_test)\n",
    "        print(\"best parameters : {}\".format(grid_search.best_params_))\n",
    "        \n",
    "        predicted = grid_search.predict(X_test)\n",
    "        print(confusion_matrix(y_test, predicted))\n",
    "        print(model_evaluation(y_test, predicted))\n",
    "\n",
    "        #print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
    "        print('='*40)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def model_evaluation(label, predict):\n",
    "    cf_matrix = confusion_matrix(label, predict)\n",
    "    Accuracy = (cf_matrix[0][0] + cf_matrix[1][1]) / sum(sum(cf_matrix))\n",
    "    Precision = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[0][1])\n",
    "    Recall = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[1][0])\n",
    "    Specificity = cf_matrix[0][0] / (cf_matrix[0][0] + cf_matrix[0][1])\n",
    "    F1_Score = (2 * Recall * Precision) / (Recall + Precision)\n",
    "    \n",
    "    print(\"Accuracy: \", round(Accuracy,3))\n",
    "    print(\"Precision: \", round(Precision,3))\n",
    "    print(\"Recall: \", round(Recall,3))\n",
    "    print(\"Specificity: \", round(Specificity,3))\n",
    "    print(\"F1-Score: \", round(F1_Score,3))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for df in [df_all_g, df_mean_g, df_median_g, df_mode_g]:\n",
    "    for column in [['Total_slp_wd_scaled','SitTime_scaled','Total_slp_wd_standard','SitTime_standard','BMI'],\n",
    "                                                    ['Total_slp_wd_scaled','SitTime_scaled','Total_slp_wd','SitTime','BMI'],\n",
    "                                                    ['Total_slp_wd_standard','SitTime_standard','Total_slp_wd','SitTime','BMI']]:\n",
    "        \n",
    "        count = count+1\n",
    "        \n",
    "        if count == 1 or count  == 2 or count == 3:\n",
    "            print('제목: df_all_g')\n",
    "        elif count == 4 or count  == 5 or count == 6:\n",
    "            print('제목: df_mean_g')\n",
    "        elif count == 7 or count  == 8 or count == 9:\n",
    "            print('제목: df_median_g')\n",
    "        elif count == 10 or count  == 11 or count == 12:\n",
    "            print('제목: df_mode_g')\n",
    "        \n",
    "        if count == 1 or count  == 4 or count == 7 or count == 10 :\n",
    "            print('데이터: 원본')\n",
    "        elif count == 2 or count  == 5 or count == 8 or count == 11:\n",
    "            print('제목: Standard')\n",
    "        elif count == 3 or count  == 6 or count == 9 or count == 12:\n",
    "            print('제목: Scaled')\n",
    "        \n",
    "        X = df.drop(column,axis=1) \n",
    "        y = df['BMI']\n",
    "\n",
    "        # test_size : 테스트 데이터셋의 비율(float)이나 갯수(int) \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=3)\n",
    "\n",
    "\n",
    "\n",
    "        #최적 파라미터 값 찾기\n",
    "        knn_classifier = KNeighborsClassifier()        \n",
    "        knn_parameters = [{\n",
    "            'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15],\n",
    "            'leaf_size': [5, 10, 15, 20, 25, 30, 35, 40],\n",
    "            'weights': ['uniform', 'distance']}]\n",
    "        # Stratified k-fold (default for classifier)\n",
    "        # n = 5 folds is default\n",
    "        grid_cv = GridSearchCV(estimator = knn_classifier, param_grid = knn_parameters, cv=5, scoring='recall')\n",
    "        grid_cv.fit(X_train, y_train)\n",
    "\n",
    "        predicted = grid_cv.predict(X_test)\n",
    "        print(confusion_matrix(y_test, predicted))\n",
    "        print(model_evaluation(y_test, predicted))\n",
    "\n",
    "        print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "        #print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
    "        print('='*40)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "count = 0\n",
    "\n",
    "for df in [df_median, df_mode]:\n",
    "    for column in [['Total_slp_wd_scaled','SitTime_scaled','Total_slp_wd_standard','SitTime_standard','BMI'],\n",
    "                                                    ['Total_slp_wd_scaled','SitTime_scaled','Total_slp_wd','SitTime','BMI'],\n",
    "                                                    ['Total_slp_wd_standard','SitTime_standard','Total_slp_wd','SitTime','BMI']]:\n",
    "        \n",
    "        count = count+1\n",
    "        \n",
    "        if count >= 1 & count <=3:\n",
    "            print('제목: df_all_b')\n",
    "        elif count>=4 & count <=6:\n",
    "            print('제목: df_mean_b')\n",
    "        elif count>=7 & count <=9:\n",
    "            print('제목: df_median_b')\n",
    "        elif count >= 10 & count <= 12:\n",
    "            print('제목: df_mode_b')\n",
    "        \n",
    "        if count == 1 or count  == 4 or count == 7 or count == 10 :\n",
    "            print('데이터: 원본')\n",
    "        elif count == 2 or count  == 5 or count == 8 or count == 11:\n",
    "            print('제목: Standard')\n",
    "        elif count == 3 or count  == 6 or count == 9 or count == 12:\n",
    "            print('제목: Scaled')\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        X = df.drop(column,axis=1) \n",
    "        y = df['BMI']\n",
    "\n",
    "        # test_size : 테스트 데이터셋의 비율(float)이나 갯수(int) \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=3)\n",
    "\n",
    "        #최적 파라미터 값 찾기\n",
    "        params = {\"loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "                  \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "                  \"penalty\" : [\"l2\", \"l1\", \"none\"],\n",
    " }\n",
    "        model = SGDClassifier(max_iter=1000)\n",
    "        clf = GridSearchCV(model, param_grid=params, cv=10)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        predicted = clf.predict(X_test)\n",
    "        print(confusion_matrix(y_test, predicted))\n",
    "        print(model_evaluation(y_test, predicted))\n",
    "\n",
    "        print('하이퍼 파라미터: ', clf.best_params_)\n",
    "        #print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
    "        print('='*40)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "count = 0\n",
    "\n",
    "for df in [df_median, df_mode]:\n",
    "    for column in [                               ['Total_slp_wd_scaled','SitTime_scaled','Total_slp_wd','SitTime','BMI'],\n",
    "                                                    ['Total_slp_wd_standard','SitTime_standard','Total_slp_wd','SitTime','BMI']]:\n",
    "        \n",
    "        count = count+1\n",
    "        \n",
    "        if count >= 1 & count <=3:\n",
    "            print('제목: df_all_b')\n",
    "        elif count>=4 & count <=6:\n",
    "            print('제목: df_mean_b')\n",
    "        elif count>=7 & count <=9:\n",
    "            print('제목: df_median_b')\n",
    "        elif count >= 10 & count <= 12:\n",
    "            print('제목: df_mode_b')\n",
    "        \n",
    "        if count == 1 or count  == 4 or count == 7 or count == 10 :\n",
    "            print('데이터: 원본')\n",
    "        elif count == 2 or count  == 5 or count == 8 or count == 11:\n",
    "            print('제목: Standard')\n",
    "        elif count == 3 or count  == 6 or count == 9 or count == 12:\n",
    "            print('제목: Scaled')\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        X = df.drop(column,axis=1) \n",
    "        y = df['BMI']\n",
    "\n",
    "        # test_size : 테스트 데이터셋의 비율(float)이나 갯수(int) \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=3)\n",
    "\n",
    "\n",
    "        #최적 파라미터 값 찾기\n",
    "        param_grid = {'C':[0.001, 0.01, 0.1], 'gamma':[0.01, 0.1,1]}\n",
    "\n",
    "        grid_search = GridSearchCV(SVC(),param_grid, cv=5, return_train_score = True)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        print(\"best parameters : {}\".format(grid_search.best_params_))\n",
    "        \n",
    "        predicted = grid_search.predict(X_test)\n",
    "        print(confusion_matrix(y_test, predicted))\n",
    "        print(model_evaluation(y_test, predicted))\n",
    "\n",
    "        #print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
    "        print('='*40)\n",
    "        print()\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
